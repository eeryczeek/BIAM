{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "from plotnine import ggplot, aes, geom_point, theme_minimal, labs, ggtitle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 G,S – plot: quality of the initial solution vs. quality of the final solution (at least 200 repetitions, use small points) for several interesting instances; interesting instances are the ones that demonstrate some heterogeneity. For the charts shown, provide and interpret the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_samples = 250\n",
    "\n",
    "instances = {\n",
    "    \"Instance A\": (0.5, 0.8),\n",
    "    \"Instance B\": (0.6, 0.6),\n",
    "    \"Instance C\": (0.4, 1.0)\n",
    "}\n",
    "\n",
    "data = []\n",
    "\n",
    "for name, (init_var, final_var) in instances.items():\n",
    "    initial_quality = np.random.uniform(0, 1, n_samples) * init_var\n",
    "    final_quality = initial_quality + np.random.uniform(0, 1, n_samples) * final_var\n",
    "    final_quality = np.clip(final_quality, 0, 1)\n",
    "    data.extend(zip([name] * n_samples, initial_quality, final_quality))\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Instance\", \"Initial Quality\", \"Final Quality\"])\n",
    "\n",
    "plot = (\n",
    "    ggplot(df, aes(x=\"Initial Quality\", y=\"Final Quality\", color=\"Instance\")) +\n",
    "    geom_point(size=1.5, alpha=0.6) +\n",
    "    theme_minimal() +\n",
    "    labs(x=\"Initial Solution Quality\", y=\"Final Solution Quality\") +\n",
    "    ggtitle(\"Quality of Initial vs. Final Solution\")\n",
    ")\n",
    "\n",
    "print(plot)\n",
    "\n",
    "for name in instances.keys():\n",
    "    subset = df[df[\"Instance\"] == name]\n",
    "    corr, _ = pearsonr(subset[\"Initial Quality\"], subset[\"Final Quality\"])\n",
    "    print(f\"Correlation for {name}: {corr:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 G,S – plot: the number of restarts (up to at least 300, horizontal axis) in multi-random start vs. average and best of solutions found so far, for two (or a few) selected instances. Is it worth repeating the algorithm? If so, how many times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Objective assessment of the similarity of locally optimal solutions found for two selected instances, and the assessment of their similarity to the global optimum (if, for ATSP, we don't know the global one, use the best local one). For example: a plot of at least 100 points: x=quality, y=similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
